{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Quickly build a random active inference agent, give it an observation and have it do hidden state and policy inference \"\"\"\n",
    "\n",
    "import pymdp\n",
    "from pymdp import utils\n",
    "from pymdp.agent import Agent\n",
    "\n",
    "num_obs = [3, 5] # observation modality dimensions\n",
    "num_states = [4, 2, 3] # hidden state factor dimensions\n",
    "num_controls = [4, 1, 1] # control state factor dimensions\n",
    "A_array = utils.random_A_matrix(num_obs, num_states) # create sensory likelihood (A matrix)\n",
    "B_array = utils.random_B_matrix(num_states, num_controls) # create transition likelihood (B matrix)\n",
    "\n",
    "C_vector = utils.obj_array_uniform(num_obs) # uniform preferences\n",
    "\n",
    "# instantiate a quick agent using your A, B and C arrays\n",
    "my_agent = Agent( A = A_array, B = B_array, C = C_vector)\n",
    "\n",
    "# give the agent a random observation and get the optimized posterior beliefs\n",
    "\n",
    "observation = [1, 4] # a list specifying the indices of the observation, for each observation modality\n",
    "\n",
    "qs = my_agent.infer_states(observation) # get posterior over hidden states (a multi-factor belief)\n",
    "\n",
    "# Do active inference\n",
    "\n",
    "q_pi, neg_efe = my_agent.infer_policies() # return the policy posterior and return (negative) expected free energies of each policy as well\n",
    "\n",
    "action = my_agent.sample_action() # sample an action from the posterior over policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0.1877081 , 0.28226447, 0.29128603, 0.2387414 ]),\n",
       "       array([0.46576659, 0.53423341]),\n",
       "       array([0.16971577, 0.54506928, 0.28521495])], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymdp\n",
    "from pymdp import utils\n",
    "from pymdp.agent import Agent\n",
    "\n",
    "num_obs = 32 * [2] # observation modality dimensions\n",
    "num_states = [4, 2, 3, 2] # hidden state factor dimensions\n",
    "num_controls = 4 * [2] # control state factor dimensions\n",
    "A_array = utils.random_A_matrix(num_obs, num_states) # create sensory likelihood (A matrix)\n",
    "B_array = utils.random_B_matrix(num_states, num_controls) # create transition likelihood (B matrix)\n",
    "\n",
    "C_vector = utils.obj_array_uniform(num_obs) # uniform preferences\n",
    "\n",
    "# instantiate a quick agent using your A, B and C arrays\n",
    "my_agent = Agent( A = A_array, B = B_array, C = C_vector)\n",
    "\n",
    "# give the agent a random observation and get the optimized posterior beliefs\n",
    "\n",
    "observation = 32 * [0] # a list specifying the indices of the observation, for each observation modality\n",
    "\n",
    "qs = my_agent.infer_states(observation) # get posterior over hidden states (a multi-factor belief)\n",
    "\n",
    "# Do active inference\n",
    "\n",
    "q_pi, neg_efe = my_agent.infer_policies() # return the policy posterior and return (negative) expected free energies of each policy as well\n",
    "\n",
    "action = my_agent.sample_action() # sample an action from the posterior over policies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymdp\n",
    "from pymdp import utils\n",
    "from pymdp.agent import Agent\n",
    "\n",
    "num_obs = [2,2,2,2] # eight stimulation sites that can either be activated or not\n",
    "#later I'll experiment with higher \"resolution\".\n",
    "num_states = [3, 3] # 5 paddle positions, 5 ball vertical positions, 3 ball 'proximities'  \n",
    "num_controls = [2, 1] # 2 possible actions: up or down (affects paddle positions), 1 and 1 controls corresponding to the uninfluenced hidden states.\n",
    "A_array = utils.random_A_matrix(num_obs, num_states) # create sensory likelihood (A matrix)\n",
    "B_array = utils.random_B_matrix(num_states, num_controls) # create transition likelihood (B matrix)\n",
    "\n",
    "C_vector = utils.obj_array_uniform(num_obs) # uniform preferences\n",
    "\n",
    "# instantiate a quick agent using your A, B and C arrays\n",
    "my_agent = Agent( A = A_array, B = B_array, C = C_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
